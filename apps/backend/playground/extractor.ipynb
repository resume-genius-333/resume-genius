{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c796a00",
   "metadata": {},
   "source": [
    "# Sample Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1f4b5",
   "metadata": {},
   "source": [
    "## Setup Path\n",
    "\n",
    "We add the directory so that we could import the files under `src` properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e26e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the backend directory to the Python path\n",
    "backend_dir = Path.cwd().parent\n",
    "sys.path.insert(0, str(backend_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6506587",
   "metadata": {},
   "source": [
    "## Import and load the `.env` file. \n",
    "\n",
    "For the `.env` file, you may find the template in the `.env.example` under the `backend` directory. \n",
    "\n",
    "For the `LITELLM_BASE_URL`, it should be `127.0.0.1:4000` in our app's case. Note that do not use `0.0.0.0` for somehow that does not work. \n",
    "\n",
    "For the `LITELLM_API_KEY`, it should be a **virtual key** created from the LiteLLM ui available at [this url](127.0.0.1:4000/ui). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0579b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=os.environ.get('LITELLM_BASE_URL'),\n",
    "    api_key=os.environ.get('LITELLM_API_KEY'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4a17e",
   "metadata": {},
   "source": [
    "## Upload the PDF File\n",
    "\n",
    "This one makes use of the files API to upload the file to the remote. This will give us an `upload` object that has an `file_id` that which we can reference. \n",
    "\n",
    "Note that try not to upload for many times, and try to delete the file that you upload after testing. Otherwise, the ghost files would cause extra money. (negilible for testing purposes, but still.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525ecd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-CqHBSiKG8GPEgB9dMmDK1T', bytes=50919, created_at=1755433787, filename='sample1.pdf', object='file', purpose='user_data', status='processed', expires_at=None, status_details=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload = await client.files.create(\n",
    "    file=Path('./files/sample1.pdf'),\n",
    "    purpose='user_data',\n",
    ")\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1b3e9",
   "metadata": {},
   "source": [
    "## Extract with Structured Output\n",
    "\n",
    "This is the way how we are extracting the content with structured output. Be aware that this one only extracts a single EducationLLMSchema, but in some resumes, there may be many education experiences worth noting. Hence, this is just a demo. \n",
    "\n",
    "For reasoning, probably we won't need it. I just put it there for fun. \n",
    "\n",
    "The type of `output` is rather complicated. Inspect it carefully. **I think we could try use `instructor` for simpler output schemas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cc30c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.schemas.llm.education import EducationLLMSchema\n",
    "\n",
    "output = await client.responses.parse(\n",
    "    model='gpt-5-mini',\n",
    "    text_format=EducationLLMSchema,\n",
    "    reasoning={\n",
    "        'effort': 'medium',\n",
    "    },\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'input_text',\n",
    "                    'text': 'Help extract the education experience of this user.'\n",
    "                },\n",
    "                {\n",
    "                    'type': 'input_file',\n",
    "                    'file_id': upload.id\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69b2b7",
   "metadata": {},
   "source": [
    "## Extract Out the Structured Output\n",
    "\n",
    "This part extracts out the content of the structured output. Note how complicated this is -- we should go with `instructor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70093182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"institution_name\": \"National University of Singapore\",\n",
      "  \"degree\": \"bachelor\",\n",
      "  \"field_of_study\": \"Computer Science\",\n",
      "  \"focus_area\": \"Selected for NUS Overseas College (NOC) Stockholm â€” year-long exchange and overseas internship; participated in classes at KTH Royal Institute of Technology and Stockholm School of Economics\",\n",
      "  \"start_date\": \"August 2021\",\n",
      "  \"end_date\": \"December 2025 (Expected)\",\n",
      "  \"gpa\": 4.71,\n",
      "  \"max_gpa\": 5.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output_items = output.output\n",
    "for item in output_items:\n",
    "    if item.type == 'message':\n",
    "        content_items = item.content\n",
    "        for content in content_items:\n",
    "            if content.type == 'output_text':\n",
    "                print(content.parsed.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3852e0",
   "metadata": {},
   "source": [
    "## Delete the Files\n",
    "\n",
    "Remember to delete the file uploaded so that it does not cost us extra money. However, no worries if you forget, we can always delete it in batch APIs later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e41aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AsyncCursorPage[FileObject](data=[], has_more=False, object='list', first_id='file-WFbaryWgWXk67jeJpYYvmU', last_id='file-CgdqFDxQNrftBzWZYLAVLTro')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.files.delete(upload.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
